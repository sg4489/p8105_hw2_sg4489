p8105_hw2_sg4489
================
sg4489
2024-09-30

``` r
# Import required packages
library(tidyverse)
library(readxl)
library(dplyr)
library(knitr)
```

# Problem 1: NYC Transit data

``` r
# Read and clean the data
transit_data <- read_csv(
  "data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", show_col_types = FALSE) %>% 
  select(line = 'Line', 
         station_name = 'Station Name', 
         station_latitude = 'Station Latitude', 
         station_longitude = 'Station Longitude', 
         Route1, Route2, Route3, Route4, Route5, Route6, Route7, Route8, Route9, Route10, Route11,  
         entry = Entry, 
         vending = Vending, 
         entrance_type = 'Entrance Type', 
         ada_compliance = ADA) %>% 
  # Convert the entry variable from character (YES vs NO) to a logical variable
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE)) %>% 
  unite("routes_served", Route1:Route11, sep = ",", na.rm = TRUE, remove = TRUE) 

# Dimensions of the cleaned dataset
transit_data_summary <- transit_data %>% 
  summarise(rows = n(), columns = ncol(.))
```

The resulting dataset has a dimension of 1868 rows and 9 columns.

This dataset contains information about the entrances and exits of NYC
subway stations, with variables including the subway line(`line`),
station name(`station_name`), station latitude and
longtitude(`station_latitude` and `station longtitude`), routes
served(`routes_served`), whether entry is allowed(`entry`), vending
machine availability(`vending`), entrance type(`entrance_type`), and ADA
compliance(\`ada_compliance).

The data cleaning steps included selecting columns, renaming them for
clarity, and convert the entry variable(`entry`) from character (YES vs
NO) to a logical variable(`TRUE`/`FALSE`).

The dataset is tidy because each row represent a single entrance/exit,
each colum is a distinct variable, and each cell contains a single
value.

## Answer the following questions using these data:

### How many distinct stations are there?

``` r
distinct_stations <- transit_data %>% 
  distinct(line, station_name) %>% 
  count()
```

There are 465 distinct stations.

### How many stations are ADA compliant?

``` r
ada_compliant_stations <- transit_data %>% 
  filter(ada_compliance == TRUE) %>% 
  distinct(line, station_name) %>% 
  count()
```

There are 84 ADA compliant stations.

### What proportion of station entrances / exits without vending allow entrance?

``` r
entrances_without_vending <- transit_data %>% 
  filter(vending == "NO" & entry == TRUE) %>% 
  count()

total_no_vending <- transit_data %>% 
  filter(vending == "NO") %>%
  count()

no_vending_entrance_propotion <- entrances_without_vending / total_no_vending
```

The propotion of station entrances / exits without vending allow
entrance is 37.704918 %.

## Reformat data so that route number and route name are distinct variables.

``` r
transit_data_reformat <- transit_data %>% 
  mutate(
    route_number = ifelse(str_detect(routes_served, "[0-9]+$"), routes_served, NA),
    route_name = ifelse(str_detect(routes_served, "[A-za-z]+$"), routes_served, NA),
  )
```

In this way, the route name and route number are separated.

### How many distinct stations serve the A train?

``` r
transit_data_long <- transit_data %>%
  separate_rows(routes_served, sep = ",") %>%
  distinct(line, station_name, routes_served, .keep_all = TRUE)

stations_serving_A <- transit_data_long %>%
  filter(routes_served == "A") %>%
  distinct(station_name, line) %>%
  count()
```

There are 60 stations serve the A train.

### Of the stations that serve the A train, how many are ADA compliant?

``` r
ada_compliant_A_stations <- transit_data_long %>%
  filter(routes_served == "A", ada_compliance == TRUE) %>%
  distinct(station_name, line) %>%
  count()
```

17 stations serve the A train are ADA compliant.

# Problem 2: Mr. Trash Wheel dataset

## Read and clean datasets

### Read Mr. Trash Wheel data

``` r
mr_trash_wheel <- suppressMessages(
  read_excel(
    "data/202409 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", skip = 1, 
    col_types = c("text", "text", "numeric", "text", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric")) %>% 
    janitor::clean_names() %>% # Clean and normalize column names
    filter(!is.na(dumpster)) %>% # Filter out lines without "dumpster" information
    mutate(
      trash_wheel = "Mr. Trash Wheel",
      # Round and converts the number of sports balls to nearest integer variable
      sports_balls = as.integer(round(sports_balls, 0))))

# Detection and remove columns with NA in mr_trash_wheel
if (all(is.na(mr_trash_wheel$x15)) && all(is.na(mr_trash_wheel$x16))) 
  mr_trash_wheel <- mr_trash_wheel %>% select(-x15, -x16)
```

### Read Professor Trash Wheel data

``` r
prof_trash_wheel <- read_excel(
  "data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", skip = 1, 
  col_types = c("text", "text", "numeric", "text", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric")) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(
    trash_wheel = "Professor Trash Wheel") 
```

### Read Gwynnda Trash Wheel data

``` r
gwynnda_trash_wheel <- read_excel(
  "data/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", skip = 1, 
  col_types = c("text", "text", "numeric", "text", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric")) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(
    trash_wheel = "Gwynnda Trash Wheel")
```

## Merge datasets

``` r
# View the remain column names
mr_cols <- colnames(mr_trash_wheel)
prof_cols <- colnames(prof_trash_wheel)
gwynnda_cols <- colnames(gwynnda_trash_wheel)

# Find common columns of three datasets
common_cols <- Reduce(
  intersect,list(mr_cols, prof_cols, gwynnda_cols))
cat("Common columns of the three sheet are: ", paste(common_cols, collapse = ", "), "\n")
```

    ## Common columns of the three sheet are:  dumpster, month, year, date, weight_tons, volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts, plastic_bags, wrappers, homes_powered, trash_wheel

``` r
# Find the difference between Mr. Trash Wheel and other datasets
diff_mr_prof <- setdiff(mr_cols, prof_cols)
diff_mr_gwynnda <- setdiff(mr_cols, gwynnda_cols)
cat("The different columns between mr_trash_wheel and prof_trash_wheel are: ", 
    paste(diff_mr_prof, collapse = ","), "\n")
```

    ## The different columns between mr_trash_wheel and prof_trash_wheel are:  sports_balls

``` r
cat("The different columns between mr_trash_wheel and gwynnda_trash_wheel are: ", 
    paste(diff_mr_gwynnda, collapse = ","), "\n")
```

    ## The different columns between mr_trash_wheel and gwynnda_trash_wheel are:  glass_bottles,sports_balls

``` r
# Merge three datasets
combined_trash_wheel <- bind_rows(mr_trash_wheel, prof_trash_wheel, gwynnda_trash_wheel)

# Move the trash wheel to the first column for easier viewing
combined_trash_wheel <- combined_trash_wheel %>% select(trash_wheel, everything())
```

## Describe data

``` r
# Get the number of observations in the result dataset
total_observations <- nrow(combined_trash_wheel)

# Calculate the total weight of trash collected by Professor Trash Wheel
total_weight_prof <- combined_trash_wheel %>% 
  filter(trash_wheel == "Professor Trash Wheel") %>% 
  summarise(total_weight = sum(weight_tons, na.rm = TRUE)) %>% 
  pull(total_weight)

# Calculate the total number of cigarette butts collected by Gwynnda in June 2022
cigarette_butts_gwynnda_2022 <- combined_trash_wheel %>% 
  filter(trash_wheel == "Gwynnda Trash Wheel" & year == 2022, month == "June") %>% 
  summarise(total_cigarette_butts = sum(cigarette_butts, na.rm = TRUE)) %>% 
  pull(total_cigarette_butts)
```

This dataset contains a total of 912 observations, with key variables
such as year and month (indicating time), weight_tons (weight of trash
in tons), and cigarette_butts (number of cigarette butts). Professor
Trash Wheel collected a total of 216.26 tons of trash, while Gwynnda
collected 18120 cigarette butts in June 2022. These data provide useful
insights into the trash collected by different Trash Wheels over time.

# Problem 3: Great British Bake Off

## Part I

### Import, clean, tidy, and otherwise wrangle each of these datasets

``` r
# Import datasets
bakers <- read_csv("data/gbb_datasets/bakers.csv", show_col_types = FALSE)
bakes <- read_csv("data/gbb_datasets/bakes.csv", show_col_types = FALSE)
results <- read_csv("data/gbb_datasets/results.csv", skip = 2, show_col_types = FALSE)
```

1.  Cleaning and organizing the bakers dataset and splitting the baker’s
    name into first and last Names. This way, when merging data sets, we
    can better match the other two data sets.

``` r
# For bakers: 
bakers <- bakers %>% 
  janitor::clean_names() %>% 
  arrange(series)

# Separate the first name and last name of the Baker Name in the baker 
bakers <- bakers %>%
  separate(`baker_name`, into = c("first_name", "last_name"), sep = " ", extra = "merge")
```

2.  Cleaning and organizing the bakes dataset. Similar to the bakers
    dataset, this cleans the column names and sorts the bakes data by
    the series column. The person who is “Jo” in this dataset appears as
    Jo in the other two datasets, so we want to remove ““.

``` r
# For bakes: 
bakes <- bakes %>% 
  janitor::clean_names() %>% 
  arrange(series)

# Remove the "" in the baker column
bakes <- bakes %>%
  mutate(baker = str_replace_all(baker, '"', ''))
```

3.  Cleaning and organizing the results dataset. Again, the results
    dataset undergoes the same cleaning and sorting process using
    clean_names() and arrange(series).

``` r
# For results: 
results <- results %>% 
  janitor::clean_names() %>% 
  arrange(series)
```

This prepares the data to be merged or used in subsequent analysis
steps, ensuring that the datasets have a consistent format and
structure.

### Check for completeness and correctness across datasets

We use anti_join(x, y, by = …): Finds rows in x that do not have
matching rows in y.

1.  Identify discrepancies between results and bakes.

missing_in_results: Identifies bakers and episodes present in bakes but
not in results.

``` r
missing_in_results <- anti_join(bakes, results, by = c("series", "episode", "baker"))
missing_in_results
```

    ## # A tibble: 8 × 5
    ##   series episode baker signature_bake                               show_stopper
    ##    <dbl>   <dbl> <chr> <chr>                                        <chr>       
    ## 1      2       1 Jo    Chocolate Orange CupcakesOrange and Cardamo… Chocolate a…
    ## 2      2       2 Jo    Caramelised Onion, Gruyere and Thyme Quiche  Raspberry a…
    ## 3      2       3 Jo    Stromboli flavored with Mozzarella, Ham, an… Unknown     
    ## 4      2       4 Jo    Lavender Biscuits                            Blueberry M…
    ## 5      2       5 Jo    Salmon and Asparagus Pie                     Apple and R…
    ## 6      2       6 Jo    Rum and Raisin Baked Cheesecake              Limoncello …
    ## 7      2       7 Jo    Raspberry & Strawberry Mousse Cake           Pain Aux Ra…
    ## 8      2       8 Jo    Raspberry and Blueberry Mille Feuille        Mini Victor…

missing_in_bakers: Finds bakers listed in results but not present in the
bakers dataset.

``` r
missing_in_bakers <- anti_join(results, bakers, by = c("series", "baker" = "first_name"))
missing_in_bakers
```

    ## # A tibble: 8 × 5
    ##   series episode baker  technical result    
    ##    <dbl>   <dbl> <chr>      <dbl> <chr>     
    ## 1      2       1 Joanne        11 IN        
    ## 2      2       2 Joanne        10 IN        
    ## 3      2       3 Joanne         1 IN        
    ## 4      2       4 Joanne         8 IN        
    ## 5      2       5 Joanne         6 IN        
    ## 6      2       6 Joanne         1 STAR BAKER
    ## 7      2       7 Joanne         3 IN        
    ## 8      2       8 Joanne         1 WINNER

2.  Identify discrepancies between results and bakers.

Find rows in results that have bakers not present in the bakers dataset.

``` r
missing_in_bakers <- anti_join(results, bakers, by = c("series", "baker" = "first_name"))
missing_in_bakers
```

    ## # A tibble: 8 × 5
    ##   series episode baker  technical result    
    ##    <dbl>   <dbl> <chr>      <dbl> <chr>     
    ## 1      2       1 Joanne        11 IN        
    ## 2      2       2 Joanne        10 IN        
    ## 3      2       3 Joanne         1 IN        
    ## 4      2       4 Joanne         8 IN        
    ## 5      2       5 Joanne         6 IN        
    ## 6      2       6 Joanne         1 STAR BAKER
    ## 7      2       7 Joanne         3 IN        
    ## 8      2       8 Joanne         1 WINNER

Find rows in bakers that are not present in results.

``` r
missing_in_results_for_bakers <- anti_join(bakers, results, by = c("series", "first_name" = "baker"))
missing_in_results_for_bakers
```

    ## # A tibble: 1 × 6
    ##   first_name last_name series baker_age baker_occupation hometown    
    ##   <chr>      <chr>      <dbl>     <dbl> <chr>            <chr>       
    ## 1 Jo         Wheatley       2        41 Housewife        Ongar, Essex

3.  Identify discrepancies between bakes and bakers.

Find rows in bakes that have bakers not present in the bakers dataset.

``` r
missing_bakers_in_bakes <- anti_join(bakes, bakers, by = c("series", "baker" = "first_name"))
missing_bakers_in_bakes
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, baker <chr>,
    ## #   signature_bake <chr>, show_stopper <chr>

Find rows in bakers that are not present in bakes.

``` r
missing_in_bakes_for_bakers <- anti_join(bakers, bakes, by = c("series", "first_name" = "baker"))
missing_in_bakes_for_bakers
```

    ## # A tibble: 25 × 6
    ##    first_name last_name       series baker_age baker_occupation         hometown
    ##    <chr>      <chr>            <dbl>     <dbl> <chr>                    <chr>   
    ##  1 Antony     Amourdoux            9        30 Banker                   London  
    ##  2 Briony     Williams             9        33 Full-time parent         Bristol 
    ##  3 Dan        Beasley-Harling      9        36 Full-time parent         London  
    ##  4 Imelda     McCarron             9        33 Countryside recreation … County …
    ##  5 Jon        Jenkins              9        47 Blood courier            Newport 
    ##  6 Karen      Wright               9        60 In-store sampling assis… Wakefie…
    ##  7 Kim-Joy    Hewlett              9        27 Mental health specialist Leeds   
    ##  8 Luke       Thompson             9        30 Civil servant/house and… Sheffie…
    ##  9 Manon      Lagrave              9        26 Software project manager London  
    ## 10 Rahul      Mandal               9        30 Research scientist       Rotherh…
    ## # ℹ 15 more rows

### Merge to create a single, final dataset and organize this so that variables and observations are in meaningful orders

Now let’s combines multiple datasets (results, bakes, and bakers) into a
single, unified dataset named final_data.

1.  Combining results and bakes using full_join. The full_join merges
    series, episode, and baker. This means all rows from both datasets
    are included, even if there isn’t a perfect match, and missing
    values will be filled with NA.

``` r
# Combine results and bakes
combined_data <- results %>%
  full_join(bakes, by = c("series" = "series", "episode" = "episode", "baker" = "baker"))
```

2.  Combining combined_data with bakers. Another full_join is used, this
    time merging on the columns series and baker (matching first_name in
    the bakers dataset). After the merge, the baker column from
    combined_data is renamed to first_name for clarity and consistency.

``` r
# Continue combine bakers dataset
final_data <- combined_data %>%
  full_join(bakers, by = c("series" = "series", "baker" = "first_name")) %>% 
  rename(first_name = baker)
```

3.  Organizing the columns in a meaningful order. The resulting
    final_data dataset contains all relevant details about each
    contestant, their performance, and demographic information,
    organized in a way that’s ready for further analysis or reporting.

``` r
# Organize variables and observations in meaningful orders
final_data <- final_data %>%
  select(series, episode, first_name, last_name, baker_occupation, baker_age, hometown, 
         technical, result, signature_bake, show_stopper)
```

4.  Export the final_data.

``` r
# Export the final_data as a CSV in the directory containing the original dataset
write_csv(final_data, file.path(getwd(), "data","gbb_datasets","final_data.csv"))
```

### Briefly discuss the final dataset.

The final_data dataset is a comprehensive combination of the results,
bakes, and bakers datasets from the Great British Bake Off. It captures
detailed information about each contestant’s participation across all
seasons and episodes.  
Key Points:  
1. Structure:  
The dataset consists of multiple columns capturing essential information
for each baker and their performance across different episodes and
seasons.  
The columns include series (season number), episode (episode number),
first_name, last_name (baker’s name), baker_occupation, baker_age,
hometown, technical (technical challenge rank), result (whether the
baker was in, out, etc.), signature_bake (description of their signature
bake), and show_stopper (description of their showstopper bake).  
2. Data Organization:  
The dataset is sorted by series and episode, making it easy to track the
progress of each season and episode sequentially.  
All relevant data is combined into a single data frame, eliminating the
need to reference multiple data sources.  
3. Completeness:  
The full_join operations ensured that no data was lost, even if some
entries were missing in one or more original datasets. This means that
the dataset will have NA values where data was not available for certain
bakers or episodes, preserving all possible information.  
4. Usability:  
The final_data dataset is ready for further analysis, such as
identifying trends, comparing the performance of different bakers, and
visualizing the distribution of “Star Baker” winners across seasons.  
The dataset is well-prepared for generating insights into how different
bakers performed in signature, technical, and showstopper challenges.

## Part II

### Create a table

``` r
# Filter for winners in Seasons 5 to 10
season_5_to_10 <- final_data %>%
  filter(series >= 5 & series <= 10) %>%
  select(series, episode, first_name, result) %>%
  filter(result == "WINNER" | result == "STAR BAKER") %>%
  arrange(series, episode)

# Create a table for Winners from Season 5 to 10
kable(
  season_5_to_10,
  col.names = c("season", "episode", "bakers", "result"),
  caption = "Star Baker and Winners from Season 5 to 10")
```

| season | episode | bakers    | result     |
|-------:|--------:|:----------|:-----------|
|      5 |       1 | Nancy     | STAR BAKER |
|      5 |       2 | Richard   | STAR BAKER |
|      5 |       3 | Luis      | STAR BAKER |
|      5 |       4 | Richard   | STAR BAKER |
|      5 |       5 | Kate      | STAR BAKER |
|      5 |       6 | Chetna    | STAR BAKER |
|      5 |       7 | Richard   | STAR BAKER |
|      5 |       8 | Richard   | STAR BAKER |
|      5 |       9 | Richard   | STAR BAKER |
|      5 |      10 | Nancy     | WINNER     |
|      6 |       1 | Marie     | STAR BAKER |
|      6 |       2 | Ian       | STAR BAKER |
|      6 |       3 | Ian       | STAR BAKER |
|      6 |       4 | Ian       | STAR BAKER |
|      6 |       5 | Nadiya    | STAR BAKER |
|      6 |       6 | Mat       | STAR BAKER |
|      6 |       7 | Tamal     | STAR BAKER |
|      6 |       8 | Nadiya    | STAR BAKER |
|      6 |       9 | Nadiya    | STAR BAKER |
|      6 |      10 | Nadiya    | WINNER     |
|      7 |       1 | Jane      | STAR BAKER |
|      7 |       2 | Candice   | STAR BAKER |
|      7 |       3 | Tom       | STAR BAKER |
|      7 |       4 | Benjamina | STAR BAKER |
|      7 |       5 | Candice   | STAR BAKER |
|      7 |       6 | Tom       | STAR BAKER |
|      7 |       7 | Andrew    | STAR BAKER |
|      7 |       8 | Candice   | STAR BAKER |
|      7 |       9 | Andrew    | STAR BAKER |
|      7 |      10 | Candice   | WINNER     |
|      8 |       1 | Steven    | STAR BAKER |
|      8 |       2 | Steven    | STAR BAKER |
|      8 |       3 | Julia     | STAR BAKER |
|      8 |       4 | Kate      | STAR BAKER |
|      8 |       5 | Sophie    | STAR BAKER |
|      8 |       6 | Liam      | STAR BAKER |
|      8 |       7 | Steven    | STAR BAKER |
|      8 |       8 | Stacey    | STAR BAKER |
|      8 |       9 | Sophie    | STAR BAKER |
|      8 |      10 | Sophie    | WINNER     |
|      9 |       1 | Manon     | STAR BAKER |
|      9 |       2 | Rahul     | STAR BAKER |
|      9 |       3 | Rahul     | STAR BAKER |
|      9 |       4 | Dan       | STAR BAKER |
|      9 |       5 | Kim-Joy   | STAR BAKER |
|      9 |       6 | Briony    | STAR BAKER |
|      9 |       7 | Kim-Joy   | STAR BAKER |
|      9 |       8 | Ruby      | STAR BAKER |
|      9 |       9 | Ruby      | STAR BAKER |
|      9 |      10 | Rahul     | WINNER     |
|     10 |       1 | Michelle  | STAR BAKER |
|     10 |       2 | Alice     | STAR BAKER |
|     10 |       3 | Michael   | STAR BAKER |
|     10 |       4 | Steph     | STAR BAKER |
|     10 |       5 | Steph     | STAR BAKER |
|     10 |       6 | Steph     | STAR BAKER |
|     10 |       7 | Henry     | STAR BAKER |
|     10 |       8 | Steph     | STAR BAKER |
|     10 |       9 | Alice     | STAR BAKER |
|     10 |      10 | David     | WINNER     |

Star Baker and Winners from Season 5 to 10

### Comment on this table

``` r
# Find the bakers with the most "Star Baker" titles in each season
most_star_bakers <- season_5_to_10 %>% 
  filter(result == "STAR BAKER") %>% 
  group_by(series, first_name) %>% 
  summarise(star_baker_count = n()) %>% 
  arrange(series, desc(star_baker_count)) %>% 
  slice(1) %>% 
  ungroup() 
```

    ## `summarise()` has grouped output by 'series'. You can override using the
    ## `.groups` argument.

``` r
# Find the winner of each season
season_winners <- season_5_to_10 %>% 
  filter(result == "WINNER") %>% 
  select(series, first_name) %>% 
  arrange(series) 
```

Season 5: Richard won “Star Baker” five times, which made him a strong
contender, but Nancy ultimately won in the final episode, which was
somewhat surprising.  
Season 6: Nadiya won “Star Baker” multiple times and was crowned the
winner, indicating a predictable path to victory.  
Season 7: Candice showed strong performance, winning “Star Baker” four
times and the final episode, indicating a predictable win.  
Season 8: Sophie won “Star Baker” three times and became the winner,
showing a relatively predictable outcome.  
Season 9: Rahul’s repeated success early in the season and eventual win
made him a predictable winner.  
Season 10: Steph was a dominant contestant with four “Star Baker”
titles, but David won the final, which was a surprise.

Surprising Outcomes:  
Season 5: Richard’s five-time “Star Baker” performance didn’t lead to a
win, which was unexpected as he was the strongest contender throughout
the season.  
Season 10: Steph’s four-time “Star Baker” titles indicated she was the
favorite, but David’s win was unexpected, showcasing that the final
challenge can change the outcome drastically.

Comments on the Table:  
The table reveals that being consistently named “Star Baker” doesn’t
always guarantee a win, as seen with Richard (Season 5) and Steph
(Season 10).  
There were seasons with more predictable outcomes, like Seasons 6, 7,
and 9, where the ultimate winners showed strong, consistent performances
throughout.

## Part III

### Import, clean, tidy, and organize the viewership data in viewers.csv. Show the first 10 rows of this dataset.

``` r
# Import dataset
viewers <- read_csv("data/gbb_datasets/viewers.csv", show_col_types = FALSE)

# View the structure of the data
str(viewers)
```

    ## spc_tbl_ [10 × 11] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
    ##  $ Episode  : num [1:10] 1 2 3 4 5 6 7 8 9 10
    ##  $ Series 1 : num [1:10] 2.24 3 3 2.6 3.03 2.75 NA NA NA NA
    ##  $ Series 2 : num [1:10] 3.1 3.53 3.82 3.6 3.83 4.25 4.42 5.06 NA NA
    ##  $ Series 3 : num [1:10] 3.85 4.6 4.53 4.71 4.61 4.82 5.1 5.35 5.7 6.74
    ##  $ Series 4 : num [1:10] 6.6 6.65 7.17 6.82 6.95 7.32 7.76 7.41 7.41 9.45
    ##  $ Series 5 : num [1:10] 8.51 8.79 9.28 10.25 9.95 ...
    ##  $ Series 6 : num [1:10] 11.6 11.6 12 12.4 12.4 ...
    ##  $ Series 7 : num [1:10] 13.6 13.4 13 13.3 13.1 ...
    ##  $ Series 8 : num [1:10] 9.46 9.23 8.68 8.55 8.61 ...
    ##  $ Series 9 : num [1:10] 9.55 9.31 8.91 8.88 8.67 ...
    ##  $ Series 10: num [1:10] 9.62 9.38 8.94 8.96 9.26 ...
    ##  - attr(*, "spec")=
    ##   .. cols(
    ##   ..   Episode = col_double(),
    ##   ..   `Series 1` = col_double(),
    ##   ..   `Series 2` = col_double(),
    ##   ..   `Series 3` = col_double(),
    ##   ..   `Series 4` = col_double(),
    ##   ..   `Series 5` = col_double(),
    ##   ..   `Series 6` = col_double(),
    ##   ..   `Series 7` = col_double(),
    ##   ..   `Series 8` = col_double(),
    ##   ..   `Series 9` = col_double(),
    ##   ..   `Series 10` = col_double()
    ##   .. )
    ##  - attr(*, "problems")=<externalptr>

``` r
# Clean and check cleaned column names
viewers <- viewers %>% janitor::clean_names()
colnames(viewers)
```

    ##  [1] "episode"   "series_1"  "series_2"  "series_3"  "series_4"  "series_5" 
    ##  [7] "series_6"  "series_7"  "series_8"  "series_9"  "series_10"

``` r
# Convert all "N/A" or "NA" strings to actual NA values
viewers[viewers == "N/A" | viewers == "NA"] <- NA

# Show the first 10 rows of this dataset
head(viewers, 10)
```

    ## # A tibble: 10 × 11
    ##    episode series_1 series_2 series_3 series_4 series_5 series_6 series_7
    ##      <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>
    ##  1       1     2.24     3.1      3.85     6.6      8.51     11.6     13.6
    ##  2       2     3        3.53     4.6      6.65     8.79     11.6     13.4
    ##  3       3     3        3.82     4.53     7.17     9.28     12.0     13.0
    ##  4       4     2.6      3.6      4.71     6.82    10.2      12.4     13.3
    ##  5       5     3.03     3.83     4.61     6.95     9.95     12.4     13.1
    ##  6       6     2.75     4.25     4.82     7.32    10.1      12       13.1
    ##  7       7    NA        4.42     5.1      7.76    10.3      12.4     13.4
    ##  8       8    NA        5.06     5.35     7.41     9.02     11.1     13.3
    ##  9       9    NA       NA        5.7      7.41    10.7      12.6     13.4
    ## 10      10    NA       NA        6.74     9.45    13.5      15.0     15.9
    ## # ℹ 3 more variables: series_8 <dbl>, series_9 <dbl>, series_10 <dbl>

### What was the average viewership in Season 1? In Season 5?

``` r
# Calculate the average viewership of season 1
average_viewership_season1 <- viewers %>%
  summarise(avg_viewership = mean(`series_1`, na.rm = TRUE))
cat("The average viewership of season 1 is: ", average_viewership_season1$avg_viewership, "\n")
```

    ## The average viewership of season 1 is:  2.77

``` r
# Calculate the average viewership of season 5
average_viewership_season5 <- viewers %>%
  summarise(avg_viewership = mean(`series_5`, na.rm = TRUE))
cat("The average viewership of season 5 is: ", average_viewership_season5$avg_viewership, "\n")
```

    ## The average viewership of season 5 is:  10.0393
